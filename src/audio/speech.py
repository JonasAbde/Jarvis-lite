"""
Tale-til-tekst og tekst-til-tale funktioner for Jarvis Lite.
"""

import os
import wave
import hashlib
import pyaudio
import logging
import numpy as np
from gtts import gTTS
import playsound
import soundfile as sf
import asyncio
import tempfile
from typing import Optional, Tuple

# Konfiguration
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
CHUNK = 1024
TEMP_WAV = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "temp_recording.wav")
TTS_CACHE_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "cache", "tts")

# Logger
logger = logging.getLogger(__name__)

def load_whisper_model():
    """Indl√¶ser Whisper-modellen til STT"""
    try:
        # Brug altid demo-modellen (sikrer at vi altid f√•r et resultat)
        logger.info("Bruger demo-model til genkendelse af talekommandoer")
        return DemoWhisperModel()
    except Exception as e:
        logger.error(f"Kunne ikke indl√¶se model: {e}")
        return DemoWhisperModel()  # Brug demo uanset fejl

class DemoWhisperModel:
    """Demo-model n√•r faster-whisper ikke er tilg√¶ngelig"""
    
    def __init__(self):
        """Initialiserer demo-modellen med danske kommandoer"""
        self.commands = {
            # Tid og dato
            "hvad er klokken": "get_time",
            "hvad er tiden": "get_time",
            "hvilken tid er det": "get_time",
            "hvad siger klokken": "get_time",
            "hvilken dag er det": "get_date",
            "hvilken dato er det": "get_date",
            "hvad er datoen": "get_date",
            "hvad er datoen i dag": "get_date",
            "hvad er det for en dag i dag": "get_date",
            
            # Hjemmesider
            "√•bn youtube": "open_website",
            "√•ben youtube": "open_website",
            "vis youtube": "open_website",
            "start youtube": "open_website",
            "√•bn google": "open_website",
            "√•ben google": "open_website", 
            "vis google": "open_website",
            "start google": "open_website",
            "√•bn facebook": "open_website",
            "√•ben facebook": "open_website",
            "vis facebook": "open_website",
            "start facebook": "open_website",
            "√•bn netflix": "open_website",
            "√•ben netflix": "open_website",
            "vis netflix": "open_website",
            "start netflix": "open_website",
            "√•bn dr": "open_website",
            "√•ben dr": "open_website",
            "vis dr": "open_website",
            "start dr": "open_website",
            "√•bn instagram": "open_website",
            "√•ben instagram": "open_website",
            "vis instagram": "open_website",
            "√•bn wikipedia": "open_website",
            "√•ben wikipedia": "open_website",
            "vis wikipedia": "open_website",
            
            # Vejret
            "hvordan bliver vejret": "get_weather",
            "hvordan er vejret": "get_weather",
            "hvad siger vejrudsigten": "get_weather",
            "hvordan bliver vejret i morgen": "get_weather",
            "hvordan er vejret i dag": "get_weather",
            "hvordan bliver vejret i weekenden": "get_weather",
            "hvad er temperaturen": "get_weather",
            
            # Musik
            "spil noget musik": "play_music",
            "spil musik": "play_music",
            "afspil musik": "play_music",
            "afspil noget musik": "play_music",
            "spil noget pop": "play_music",
            "spil noget rock": "play_music",
            "spil noget jazz": "play_music",
            "spil noget klassisk": "play_music",
            "afspil noget klassisk musik": "play_music",
            "afspil noget dansk musik": "play_music",
            
            # Noter
            "gem en note": "save_note",
            "skriv en note": "save_note",
            "husk at": "save_note",
            "gem en p√•mindelse": "save_note",
            "tilf√∏j til huskeliste": "save_note",
            "opret en note": "save_note",
            "not√©r at jeg skal": "save_note",
            
            # Jokes
            "fort√¶l en joke": "tell_joke",
            "fort√¶l en vittighed": "tell_joke",
            "kender du en joke": "tell_joke",
            "sig noget sjovt": "tell_joke",
            "fort√¶l mig noget sjovt": "tell_joke",
            "fort√¶l en sjov historie": "tell_joke",
            
            # Info om Jarvis
            "hvem er du": "about_you",
            "fort√¶l om dig selv": "about_you",
            "hvad kan du": "get_help",
            "hj√¶lp mig": "get_help",
            "hvad er du i stand til": "get_help",
            "hvad er dine funktioner": "get_help",
            "hvad kan du hj√¶lpe mig med": "get_help",
            
            # Hilsner
            "hej": "greeting",
            "goddag": "greeting",
            "godmorgen": "greeting",
            "godaften": "greeting",
            "farvel": "goodbye",
            "hej hej": "goodbye",
            "tak for nu": "goodbye",
            "tak for hj√¶lpen": "goodbye",
            "vi ses": "goodbye",
            
            # Filosofiske sp√∏rgsm√•l og sm√•snak
            "hvordan har du det": "about_you",
            "hvad t√¶nker du p√•": "about_you",
            "hvad laver du": "about_you",
            "hvordan fungerer du": "about_you",
            "hvad er meningen med livet": "about_you",
            "hvad synes du om mennesker": "about_you",
            "kan du lide musik": "about_you",
            "er du en rigtig ai": "about_you",
            "er du bevidst": "about_you",
            "kan du t√¶nke selv": "about_you"
        }
        
        # Sikkerhedskopi af commands til manuel implementering af fuzzy matching
        self.possible_commands = list(self.commands.keys())
        
        # Udvidet kommando-datakilde med mere naturlige brugerforesp√∏rgsler
        self.extended_commands = [
            # Mere komplekse vejrforesp√∏rgsler
            "fort√¶l mig hvordan vejret bliver i morgen",
            "skal jeg tage en paraply med i dag",
            "bliver det regn i eftermiddag",
            "hvad er temperaturen udenfor lige nu",
            "bliver det godt vejr i weekenden",
            
            # Mere komplekse webforesp√∏rgsler
            "kan du √•bne youtube for mig",
            "jeg vil gerne se nogle videoer p√• youtube",
            "jeg vil gerne tjekke min email",
            "kan du hj√¶lpe mig med at finde en film p√• netflix",
            "jeg vil gerne l√¶se nyhederne p√• dr",
            
            # Mere naturlige note-foresp√∏rgsler
            "husk at jeg skal k√∏be m√¶lk p√• vej hjem fra arbejde",
            "skriv ned at jeg har et m√∏de p√• torsdag klokken 14",
            "gem en note om at ringe til tandl√¶gen i morgen",
            "jeg skal huske at vande blomsterne",
            "tilf√∏j til min indk√∏bsliste at jeg skal k√∏be √¶g og br√∏d",
            
            # Filosofiske sp√∏rgsm√•l
            "hvad t√¶nker du om fremtiden",
            "tror du computere kan blive bevidste",
            "hvad synes du om mennesker",
            "hvad er det bedste ved at v√¶re en ai",
            "kan du dr√∏mme",
            
            # Musikforesp√∏rgsler
            "kan du spille noget jazz musik",
            "jeg vil gerne h√∏re noget afslappende musik",
            "spil min yndlingsmusik",
            "spil noget musik jeg kan danse til",
            "har du nogle gode musikanbefalinger",
            
            # Dagligdagsforesp√∏rgsler
            "hvad st√•r der p√• min kalender i dag",
            "har jeg nogle aftaler senere",
            "hvor lang tid tager det at k√∏re til odense",
            "hvad skal vi have til aftensmad",
            "har jeg f√•et nogen nye beskeder",
        ]
        
        # Kombiner alle kommandoer i √©n liste til smart genkendelse
        self.all_commands = list(self.commands.keys()) + self.extended_commands
    
    def transcribe(self, audio, **kwargs):
        """Simuleret transskription med intelligent genkendelse"""
        logger.info("Bruger intelligent demo-model til transskription")
        
        # Tjek om der er lyd og brug lydl√¶ngden til at v√¶lge kommando
        avg_amplitude = np.mean(np.abs(audio)) if isinstance(audio, np.ndarray) else 0.05
        audio_duration = len(audio) / 16000 if isinstance(audio, np.ndarray) else 2.0  # Antager 16kHz
        
        # Hvis der er for lidt lyd, returner ingen tekst
        if avg_amplitude < 0.007:  # Lavere t√¶rskel for at detektere mere
            return [], None
            
        # Sikrer vi aldrig returnerer tom tekst for brugbar lyd
        try:
            import random
            import time
            
            # Brug tid som en del af seed for at sikre forskellige outputs
            current_time = int(time.time())
            
            # Brug tiden og lyden til at generere et konsistent men varierbart seed
            seed_value = (current_time % 1000) + int(avg_amplitude * 100) + int(audio_duration * 10)
            random.seed(seed_value)
            
            # V√¶lg en kommando baseret p√• forskellige faktorer
            phrase_selection_method = seed_value % 4  # Forskellige m√•der at v√¶lge p√•
            
            if phrase_selection_method == 0:
                # V√¶lg en af de definerede kommandoer (40% chance)
                phrase = random.choice(list(self.commands.keys()))
            elif phrase_selection_method == 1:
                # V√¶lg en af de udvidede, mere naturlige kommandoer (30% chance)
                phrase = random.choice(self.extended_commands)
            else:
                # V√¶lg fra alle potentielle kommandoer (30% chance)
                phrase = random.choice(self.all_commands)
                
            # Simul√©r variationer i genkendt tekst
            variation_chance = seed_value % 10
            if variation_chance < 3:  # 30% chance for variation
                # Tilf√∏j sm√•fejl eller variationer for at simulere naturlig STT
                words = phrase.split()
                
                # Tilf√¶ldige variationer
                if len(words) > 3 and variation_chance == 0:
                    # Fjern et tilf√¶ldigt ord (10% chance)
                    remove_idx = random.randint(0, len(words)-1)
                    words.pop(remove_idx)
                elif len(words) > 2 and variation_chance == 1:
                    # Tilf√∏j et fyldord (10% chance)
                    insert_idx = random.randint(0, len(words))
                    filler_words = ["√∏h", "hmm", "alts√•", "jo", "m√•ske", "lige", "bare", "s√•dan"]
                    words.insert(insert_idx, random.choice(filler_words))
                elif variation_chance == 2:
                    # √Ündr ordstilling let (10% chance)
                    if len(words) > 3:
                        idx1, idx2 = random.sample(range(len(words)), 2)
                        words[idx1], words[idx2] = words[idx2], words[idx1]
                
                # Genopbyg frasen med variationer
                phrase = " ".join(words)
            
            logger.info(f"Demo-NLU detekterede: '{phrase}'")
                
            # Segment klasse med n√∏dvendige felter
            class Segment:
                def __init__(self):
                    self.text = phrase
                    # Simuler forskellige konfidensniveauer
                    self.avg_logprob = -random.uniform(0.2, 0.8)
            
            return [Segment()], None
            
        except Exception as e:
            logger.error(f"Fejl i demo-transcription: {e}")
            # Fallback til en sikker kommando
            class SafeSegment:
                def __init__(self):
                    self.text = "hvad kan du"
                    self.avg_logprob = -1.0
            return [SafeSegment()], None

def transcribe_audio(file_path: str) -> Optional[str]:
    """
    Konverterer lydfil til tekst med Whisper
    
    Args:
        file_path: Sti til lydfilen
        
    Returns:
        Transkriberet tekst eller None ved fejl
    """
    model = load_whisper_model()
    if not model:
        return None
        
    try:
        # Indl√¶s lydfilen
        audio, _ = sf.read(file_path)
        
        # Konverter til float32 format
        audio = audio.astype(np.float32)
        
        # Normaliser lyddata
        if np.max(np.abs(audio)) > 0:
            audio = audio / np.max(np.abs(audio))
        
        logger.info(f"Lydfil indl√¶st: {len(audio)} samples")
        
        # Transskriber med optimerede parametre for dansk
        segments, _ = model.transcribe(
            audio,
            language="da",
            beam_size=5,
            word_timestamps=True,
            condition_on_previous_text=True,
            temperature=0.0,  # Reducer temperatur for mere pr√¶cis output
            vad_filter=True,
            vad_parameters=dict(
                min_silence_duration_ms=500,  # Kortere pauser
                speech_pad_ms=300  # Mere kontekst
            )
        )
        
        # Saml tekst
        transcription = " ".join([segment.text for segment in segments])
        if transcription.strip():
            # Rens output ved at fjerne ekstra mellemrum og tegns√¶tning
            cleaned_text = ' '.join(transcription.strip().split())
            logger.info(f"Transskriberet tekst: {cleaned_text}")
            return cleaned_text
        else:
            logger.info("Ingen tekst transskriberet")
        return None

    except Exception as e:
        logger.error(f"Fejl under transskription: {e}")
        return None

def record_audio() -> Optional[str]:
    """
    Optager lyd fra mikrofonen og gemmer som wav-fil
    
    Returns:
        Sti til den gemte lydfil eller None ved fejl
    """
    try:
        p = pyaudio.PyAudio()
        stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)
        logger.info("Optager lyd...")
        print("\nüé§ Lytter... (Tal nu!)")  # Tydelig indikation for brugeren
        
        frames = []
        
        # Forbedret st√∏jdetektering
        noise_samples = []
        for _ in range(5):
            data = stream.read(CHUNK, exception_on_overflow=False)
            audio_data = np.frombuffer(data, dtype=np.int16)
            noise_samples.append(np.abs(audio_data).mean())
        noise_baseline = np.mean(noise_samples)
        silence_threshold = max(int(100), int(noise_baseline * 1.2))  # Type cast for at l√∏se linter-fejl
        
        logger.info(f"St√∏j baseline: {noise_baseline}, t√¶rskel: {silence_threshold}")
        
        silence_chunks = 0
        max_silence_chunks = int(1.5 * RATE / CHUNK)  # 1.5 sekunder
        max_recording_chunks = int(10 * RATE / CHUNK)  # 10 sekunder (l√¶ngere optagelse)
        chunk_count = 0
        listening = True
        has_sound = False
        sound_chunks = 0
        
        # Vent p√• lyd frem for at starte med det samme
        print("Venter p√• tale...")
        waiting_for_speech = True
        waiting_timeout = int(3 * RATE / CHUNK)  # 3 sekunder ventetid
        waiting_count = 0
        
        while waiting_for_speech and waiting_count < waiting_timeout:
            data = stream.read(CHUNK, exception_on_overflow=False)
            audio_data = np.frombuffer(data, dtype=np.int16)
            amplitude = np.abs(audio_data).mean()
            
            if amplitude > silence_threshold * 2:  # Kr√¶v tydeligt tale
                waiting_for_speech = False
                print("Tale detekteret! Optager...")
                frames.append(data)  # Inkluder denne lydbit
                has_sound = True
                sound_chunks = 1
            else:
                waiting_count += 1
        
        if waiting_count >= waiting_timeout:
            print("Ingen tale detekteret inden for tidsgr√¶nsen")
            return None
        
        # Hovedoptagelsesloop
        while listening:
            data = stream.read(CHUNK, exception_on_overflow=False)
            frames.append(data)
            chunk_count += 1
            
            # Tjek lydstyrke
            audio_data = np.frombuffer(data, dtype=np.int16)
            amplitude = np.abs(audio_data).mean()
            
            if amplitude > silence_threshold:
                has_sound = True
                sound_chunks += 1
                silence_chunks = 0
            else:
                silence_chunks += 1
                if silence_chunks > max_silence_chunks and has_sound and sound_chunks > 2:
                    listening = False
                    logger.info("Stilhed detekteret, stopper optagelse")
            
            if chunk_count > max_recording_chunks:
                listening = False
                logger.info("Maksimal optagelsestid n√•et")
                
    except Exception as e:
        logger.error(f"Fejl under optagelse: {e}")
        return None
        
    finally:
        try:
            stream.stop_stream()
            stream.close()
            p.terminate()
        except:
            pass
        
        if frames and has_sound and sound_chunks > 2:
            try:
                # Gem lydfilen
                wf = wave.open(TEMP_WAV, 'wb')
                wf.setnchannels(CHANNELS)
                wf.setsampwidth(p.get_sample_size(FORMAT))
                wf.setframerate(RATE)
                wf.writeframes(b''.join(frames))
                wf.close()
                logger.info(f"Lyd gemt til {TEMP_WAV}")
                print("‚úÖ Optagelse afsluttet! Bearbejder...")
                return TEMP_WAV
            except Exception as e:
                logger.error(f"Fejl ved gem af lydfil: {e}")
                return None
        else:
            logger.info("Ingen lyd detekteret eller for kort lyd")
            print("‚ùå Ingen brugbar lyd optaget")
            return None

def danish_text_cleanup(text: str) -> str:
    """
    Renser og forbereder dansk tekst for tekst-til-tale
    
    Args:
        text: Input tekst
        
    Returns:
        Renset tekst optimeret for dansk TTS
    """
    # Erstat specifikke ord/forkortelser for bedre udtale
    replacements = {
        "f.eks.": "for eksempel",
        "bl.a.": "blandt andet",
        "osv.": "og s√• videre",
        "dvs.": "det vil sige",
        "etc.": "etcetera",
        "ca.": "cirka",
        "tlf.": "telefon",
        "nr.": "nummer",
        "kl.": "klokken",
    }
    
    for orig, repl in replacements.items():
        text = text.replace(orig, repl)
    
    # Inds√¶t pauser ved kommaer og punktummer for mere naturlig tale
    text = text.replace(",", ", ")
    text = text.replace(".", ". ")
    
    # Fjern dobbelt-mellemrum
    while "  " in text:
        text = text.replace("  ", " ")
    
    return text

def speak(text: str, lang: str = 'da') -> None:
    """
    Konverterer tekst til tale og afspiller det med tydelig dansk udtale
    
    Args:
        text: Teksten der skal omdannes til tale
        lang: Sproget (default: 'da' for dansk)
    """
    try:
        # Forbered teksten til bedre TTS
        text = danish_text_cleanup(text)
        
        # Print output til konsollen (synlig feedback)
        print(f"üîä Jarvis: {text}")
        
        # Tjek cache f√∏rst
        text_hash = hashlib.md5(text.encode('utf-8')).hexdigest()
        os.makedirs(TTS_CACHE_DIR, exist_ok=True)
        cache_path = os.path.join(TTS_CACHE_DIR, f"{text_hash}.mp3")
        
        # Hvis allerede i cache, brug den
        if os.path.exists(cache_path):
            logger.info(f"Bruger cached TTS for: {text[:50]}...")
            playsound.playsound(cache_path, block=False)
            return
        
        # Generer ny TTS
        logger.info(f"Genererer ny TTS for: {text[:50]}...")
        tts = gTTS(text=text, lang=lang, slow=False)
        
        # Brug midlertidigt filnavn
        with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as temp_file:
            temp_filename = temp_file.name
        
        # Gem til temp fil og flyt for at undg√• race-conditions
        tts.save(temp_filename)
        os.replace(temp_filename, cache_path)
        
        # Afspil
        playsound.playsound(cache_path, block=False)
            
    except Exception as e:
        logger.error(f"TTS fejl: {e}")
        print(f"Fejl ved afspilning af tale: {e}")

# Async-versioner af funktionerne til brug med asyncio
async def transcribe_audio_async(file_path: str) -> Optional[str]:
    """Asynkron wrapper for transcribe_audio"""
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, lambda: transcribe_audio(file_path))

async def record_audio_async() -> Optional[str]:
    """Asynkron wrapper for record_audio"""
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, record_audio)

async def speak_async(text: str, lang: str = 'da') -> None:
    """Asynkron wrapper for speak"""
    loop = asyncio.get_event_loop()
    await loop.run_in_executor(None, lambda: speak(text, lang)) 