"""
Tale-til-tekst og tekst-til-tale funktioner for Jarvis Lite.
"""

import os
import wave
import hashlib
import logging
import numpy as np  # type: ignore
from gtts import gTTS  # type: ignore
import playsound # type: ignore
import soundfile as sf  # type: ignore
import asyncio
from tempfile import NamedTemporaryFile
import re
from typing import Optional, Tuple, List, Dict, Any
from pathlib import Path
import torch
from faster_whisper import WhisperModel
import pygame

# Fors√∏g at importere pyaudio, med sounddevice som backup
USE_PYAUDIO = True
USE_SOUNDDEVICE = False

try:
    import pyaudio # type: ignore
except ImportError:
    USE_PYAUDIO = False
    try:
        import sounddevice as sd  # type: ignore
        USE_SOUNDDEVICE = True
        print("PyAudio ikke tilg√¶ngelig. Bruger sounddevice i stedet.")
    except ImportError:
        print("ADVARSEL: Hverken PyAudio eller sounddevice er tilg√¶ngelig. Lydoptagelse vil ikke virke.")

# Konfiguration
if USE_PYAUDIO:
    FORMAT = pyaudio.paInt16
else:
    FORMAT = 16  # For sounddevice

CHANNELS = 1
RATE = 16000
CHUNK = 1024
TEMP_WAV = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "temp_recording.wav")
TTS_CACHE_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), "cache", "tts")
VOICES_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), "data", "voices")

# Brugerdefinerede stemmer
AVAILABLE_VOICES = []  # Populeres ved initialisering
CURRENT_VOICE = None   # Aktuelt valgte stemme
DEFAULT_VOICE_ID = "default"  # Brug standard gTTS

# Logger
logger = logging.getLogger(__name__)

# Tilf√∏j en global lydafspilningsk√∏ og et flag for at spore igangv√¶rende afspilning
SPEECH_QUEUE = []  # K√∏ til ventende taleafspilninger
CURRENTLY_SPEAKING = False  # Flag der indikerer om der er en igangv√¶rende taleafspilning
SPEECH_LOCK = None  # Asyncio lock til at synkronisere taleafspilning

# Funktion til at indl√¶se tilg√¶ngelige stemmer
def initialize_voices() -> None:
    """Indl√¶ser tilg√¶ngelige stemmer fra voices-mappen"""
    global AVAILABLE_VOICES
    AVAILABLE_VOICES = []
    
    # Tilf√∏j standardstemme (gTTS)
    AVAILABLE_VOICES.append({
        "id": DEFAULT_VOICE_ID,
        "name": "Google TTS (Standard)",
        "engine": "gtts",
        "language": "da",
        "gender": "neutral",
        "path": None
    })
    
    if not os.path.exists(VOICES_DIR):
        logger.warning(f"Voices-mappe findes ikke: {VOICES_DIR}")
        return
    
    try:
        # Find brugerdefinerede stemme-mapper
        for voice_dir in os.listdir(VOICES_DIR):
            voice_path = os.path.join(VOICES_DIR, voice_dir)
            if os.path.isdir(voice_path):
                # Tjek om mappen indeholder wav-filer
                wav_files = [f for f in os.listdir(voice_path) if f.endswith('.wav')]
                if wav_files:
                    AVAILABLE_VOICES.append({
                        "id": voice_dir,
                        "name": voice_dir.capitalize(),
                        "engine": "custom",
                        "language": "da",
                        "gender": "unknown",
                        "path": voice_path,
                        "samples": [os.path.join(voice_path, f) for f in wav_files]
                    })
        
        logger.info(f"Fandt {len(AVAILABLE_VOICES)-1} brugerdefinerede stemmer")
        
    except Exception as e:
        logger.error(f"Fejl under indl√¶sning af stemmer: {e}")

# Funktion til at hente tilg√¶ngelige stemmer
def get_available_voices() -> List[Dict[str, Any]]:
    """Returnerer liste med tilg√¶ngelige stemmer"""
    if not AVAILABLE_VOICES:
        initialize_voices()
    return AVAILABLE_VOICES

# Funktion til at v√¶lge stemme
def set_voice(voice_id: str) -> bool:
    """
    V√¶lger den aktive stemme
    
    Args:
        voice_id: ID for stemmen der skal bruges
        
    Returns:
        bool: True hvis stemmen blev sat, False ved fejl
    """
    global CURRENT_VOICE
    
    # Indl√¶s stemmer hvis n√∏dvendigt
    if not AVAILABLE_VOICES:
        initialize_voices()
    
    # Find stemmen med det angivne ID
    matching_voices = [v for v in AVAILABLE_VOICES if v["id"] == voice_id]
    if matching_voices:
        CURRENT_VOICE = matching_voices[0]
        logger.info(f"Stemme sat til: {CURRENT_VOICE['name']} (ID: {CURRENT_VOICE['id']})")
        return True
    else:
        logger.warning(f"Kunne ikke finde stemme med ID: {voice_id}")
        # Brug standardstemme som fallback
        default_voice = next((v for v in AVAILABLE_VOICES if v["id"] == DEFAULT_VOICE_ID), None)
        if default_voice:
            CURRENT_VOICE = default_voice
            logger.info(f"Faldt tilbage til standardstemme: {CURRENT_VOICE['name']}")
            return True
        return False

# Funktion til at f√• den aktuelle stemme
def get_current_voice() -> Dict[str, Any]:
    """Returnerer information om den aktuelt valgte stemme"""
    global CURRENT_VOICE
    
    if not CURRENT_VOICE:
        # Indl√¶s stemmer hvis n√∏dvendigt
        if not AVAILABLE_VOICES:
            initialize_voices()
        
        # V√¶lg standardstemmen
        # Hvis standardstemmen ikke findes i AVAILABLE_VOICES, tilf√∏j den
        default_voice = next((v for v in AVAILABLE_VOICES if v["id"] == DEFAULT_VOICE_ID), None)
        if not default_voice:
            # Dette burde ikke ske, men som sikkerhed
            logger.warning("Standardstemme mangler, tilf√∏jer den igen")
            default_voice = {
                "id": DEFAULT_VOICE_ID,
                "name": "Google TTS (Standard)",
                "engine": "gtts",
                "language": "da",
                "gender": "neutral",
                "path": None
            }
            AVAILABLE_VOICES.append(default_voice)
        
        CURRENT_VOICE = default_voice
        logger.info(f"Automatisk valgt stemme: {CURRENT_VOICE['name']}")
    
    return CURRENT_VOICE

# Initialiser stemmer ved import
initialize_voices()
set_voice(DEFAULT_VOICE_ID)  # Start med standardstemmen

def load_whisper_model():
    """Indl√¶ser Whisper-modellen til STT"""
    try:
        # Brug altid demo-modellen (sikrer at vi altid f√•r et resultat)
        logger.info("Bruger demo-model til genkendelse af talekommandoer")
        return DemoWhisperModel()
    except Exception as e:
        logger.error(f"Kunne ikke indl√¶se model: {e}")
        return DemoWhisperModel()  # Brug demo uanset fejl

class DemoWhisperModel:
    """Demo-model n√•r faster-whisper ikke er tilg√¶ngelig"""
    
    def __init__(self):
        """Initialiserer demo-modellen med danske kommandoer"""
        self.commands = {
            # Tid og dato
            "hvad er klokken": "get_time",
            "hvad er tiden": "get_time",
            "hvilken tid er det": "get_time",
            "hvad siger klokken": "get_time",
            "hvilken dag er det": "get_date",
            "hvilken dato er det": "get_date",
            "hvad er datoen": "get_date",
            "hvad er datoen i dag": "get_date",
            "hvad er det for en dag i dag": "get_date",
            
            # Hjemmesider
            "√•bn youtube": "open_website",
            "√•ben youtube": "open_website",
            "vis youtube": "open_website",
            "start youtube": "open_website",
            "√•bn google": "open_website",
            "√•ben google": "open_website", 
            "vis google": "open_website",
            "start google": "open_website",
            "√•bn facebook": "open_website",
            "√•ben facebook": "open_website",
            "vis facebook": "open_website",
            "start facebook": "open_website",
            "√•bn netflix": "open_website",
            "√•ben netflix": "open_website",
            "vis netflix": "open_website",
            "start netflix": "open_website",
            "√•bn dr": "open_website",
            "√•ben dr": "open_website",
            "vis dr": "open_website",
            "start dr": "open_website",
            "√•bn instagram": "open_website",
            "√•ben instagram": "open_website",
            "vis instagram": "open_website",
            "√•bn wikipedia": "open_website",
            "√•ben wikipedia": "open_website",
            "vis wikipedia": "open_website",
            
            # Vejret
            "hvordan bliver vejret": "get_weather",
            "hvordan er vejret": "get_weather",
            "hvad siger vejrudsigten": "get_weather",
            "hvordan bliver vejret i morgen": "get_weather",
            "hvordan er vejret i dag": "get_weather",
            "hvordan bliver vejret i weekenden": "get_weather",
            "hvad er temperaturen": "get_weather",
            
            # Musik
            "spil noget musik": "play_music",
            "spil musik": "play_music",
            "afspil musik": "play_music",
            "afspil noget musik": "play_music",
            "spil noget pop": "play_music",
            "spil noget rock": "play_music",
            "spil noget jazz": "play_music",
            "spil noget klassisk": "play_music",
            "afspil noget klassisk musik": "play_music",
            "afspil noget dansk musik": "play_music",
            
            # Noter
            "gem en note": "save_note",
            "skriv en note": "save_note",
            "husk at": "save_note",
            "gem en p√•mindelse": "save_note",
            "tilf√∏j til huskeliste": "save_note",
            "opret en note": "save_note",
            "not√©r at jeg skal": "save_note",
            
            # Jokes
            "fort√¶l en joke": "tell_joke",
            "fort√¶l en vittighed": "tell_joke",
            "kender du en joke": "tell_joke",
            "sig noget sjovt": "tell_joke",
            "fort√¶l mig noget sjovt": "tell_joke",
            "fort√¶l en sjov historie": "tell_joke",
            
            # Info om Jarvis
            "hvem er du": "about_you",
            "fort√¶l om dig selv": "about_you",
            "hvad kan du": "get_help",
            "hj√¶lp mig": "get_help",
            "hvad er du i stand til": "get_help",
            "hvad er dine funktioner": "get_help",
            "hvad kan du hj√¶lpe mig med": "get_help",
            
            # Hilsner
            "hej": "greeting",
            "goddag": "greeting",
            "godmorgen": "greeting",
            "godaften": "greeting",
            "farvel": "goodbye",
            "hej hej": "goodbye",
            "tak for nu": "goodbye",
            "tak for hj√¶lpen": "goodbye",
            "vi ses": "goodbye",
            
            # Filosofiske sp√∏rgsm√•l og sm√•snak
            "hvordan har du det": "about_you",
            "hvad t√¶nker du p√•": "about_you",
            "hvad laver du": "about_you",
            "hvordan fungerer du": "about_you",
            "hvad er meningen med livet": "about_you",
            "hvad synes du om mennesker": "about_you",
            "kan du lide musik": "about_you",
            "er du en rigtig ai": "about_you",
            "er du bevidst": "about_you",
            "kan du t√¶nke selv": "about_you"
        }
        
        # Sikkerhedskopi af commands til manuel implementering af fuzzy matching
        self.possible_commands = list(self.commands.keys())
        
        # Udvidet kommando-datakilde med mere naturlige brugerforesp√∏rgsler
        self.extended_commands = [
            # Mere komplekse vejrforesp√∏rgsler
            "fort√¶l mig hvordan vejret bliver i morgen",
            "skal jeg tage en paraply med i dag",
            "bliver det regn i eftermiddag",
            "hvad er temperaturen udenfor lige nu",
            "bliver det godt vejr i weekenden",
            
            # Mere komplekse webforesp√∏rgsler
            "kan du √•bne youtube for mig",
            "jeg vil gerne se nogle videoer p√• youtube",
            "jeg vil gerne tjekke min email",
            "kan du hj√¶lpe mig med at finde en film p√• netflix",
            "jeg vil gerne l√¶se nyhederne p√• dr",
            
            # Mere naturlige note-foresp√∏rgsler
            "husk at jeg skal k√∏be m√¶lk p√• vej hjem fra arbejde",
            "skriv ned at jeg har et m√∏de p√• torsdag klokken 14",
            "gem en note om at ringe til tandl√¶gen i morgen",
            "jeg skal huske at vande blomsterne",
            "tilf√∏j til min indk√∏bsliste at jeg skal k√∏be √¶g og br√∏d",
            
            # Filosofiske sp√∏rgsm√•l
            "hvad t√¶nker du om fremtiden",
            "tror du computere kan blive bevidste",
            "hvad synes du om mennesker",
            "hvad er det bedste ved at v√¶re en ai",
            "kan du dr√∏mme",
            
            # Musikforesp√∏rgsler
            "kan du spille noget jazz musik",
            "jeg vil gerne h√∏re noget afslappende musik",
            "spil min yndlingsmusik",
            "spil noget musik jeg kan danse til",
            "har du nogle gode musikanbefalinger",
            
            # Dagligdagsforesp√∏rgsler
            "hvad st√•r der p√• min kalender i dag",
            "har jeg nogle aftaler senere",
            "hvor lang tid tager det at k√∏re til odense",
            "hvad skal vi have til aftensmad",
            "har jeg f√•et nogen nye beskeder",
        ]
        
        # Kombiner alle kommandoer i √©n liste til smart genkendelse
        self.all_commands = list(self.commands.keys()) + self.extended_commands
    
    def transcribe(self, audio, **kwargs):
        """Simuleret transskription med intelligent genkendelse"""
        logger.info("Bruger intelligent demo-model til transskription")
        
        # Tjek om der er lyd og brug lydl√¶ngden til at v√¶lge kommando
        avg_amplitude = np.mean(np.abs(audio)) if isinstance(audio, np.ndarray) else 0.05
        audio_duration = len(audio) / 16000 if isinstance(audio, np.ndarray) else 2.0  # Antager 16kHz
        
        # Meget strengere kontrol for reel lyd - kun return√©r tekst hvis der faktisk er tale
        if avg_amplitude < 0.02:  # √òget v√¶sentligt fra 0.007
            logger.info(f"Ingen tilstr√¶kkelig lyd detekteret i audio (amplitude: {avg_amplitude})")
            return [], None
            
        # For korte lyde er sandsynligvis ikke intentionel tale
        if audio_duration < 0.5:
            logger.info(f"Lyd for kort til at v√¶re tale ({audio_duration:.2f}s)")
            return [], None
        
        # I demo-tilstand returnerer vi svar baseret p√• lydl√¶ngden, 
        # men med meget h√∏jere krav til amplitude og varighed
        phrase = "hej jarvis"
        
        # Kun for gode lydpr√∏ver med tilstr√¶kkelig amplitude
        if audio_duration < 1.0:
            phrase = "ja"  # Kort lyd
        elif audio_duration < 1.5:
            phrase = "nej"  # Lidt l√¶ngere
        elif audio_duration < 2.5:
            phrase = "hvad kan du"  # Mellem
        elif audio_duration < 3.5:
            phrase = "fort√¶l en joke"  # L√¶ngere
        elif audio_duration < 5.0:  # Standard
            phrase = "hvad er klokken"
        else:
            phrase = "fort√¶l mig om dig selv"  # Lang

        logger.info(f"Demo-NLU detekterede: '{phrase}' (amplitude: {avg_amplitude:.4f}, varighed: {audio_duration:.2f}s)")
                
        # Segment klasse med n√∏dvendige felter
        class Segment:
            def __init__(self):
                self.text = phrase
                self.avg_logprob = -0.5
            
        return [Segment()], None

def transcribe_audio(file_path: str) -> Optional[str]:
    """
    Konverterer lydfil til tekst med Whisper
    
    Args:
        file_path: Sti til lydfilen
        
    Returns:
        Transkriberet tekst eller None ved fejl
    """
    model = load_whisper_model()
    if not model:
        return None
        
    try:
        # Indl√¶s lydfilen
        audio, _ = sf.read(file_path)
        
        # Konverter til float32 format
        audio = audio.astype(np.float32)
        
        # Normaliser lyddata
        if np.max(np.abs(audio)) > 0:
            audio = audio / np.max(np.abs(audio))
        
        logger.info(f"Lydfil indl√¶st: {len(audio)} samples")
        
        # Transskriber med optimerede parametre for dansk
        segments, _ = model.transcribe(
            audio,
            language="da",
            beam_size=5,
            word_timestamps=True,
            condition_on_previous_text=True,
            temperature=0.0,  # Reducer temperatur for mere pr√¶cis output
            vad_filter=True,
            vad_parameters=dict(
                min_silence_duration_ms=500,  # Kortere pauser
                speech_pad_ms=300  # Mere kontekst
            )
        )
        
        # Saml tekst
        transcription = " ".join([segment.text for segment in segments])
        if transcription.strip():
            # Rens output ved at fjerne ekstra mellemrum og tegns√¶tning
            cleaned_text = ' '.join(transcription.strip().split())
            logger.info(f"Transskriberet tekst: {cleaned_text}")
            return cleaned_text
        else:
            logger.info("Ingen tekst transskriberet")
        return None

    except Exception as e:
        logger.error(f"Fejl under transskription: {e}")
        return None

def record_audio() -> Optional[str]:
    """
    Optager lyd fra mikrofonen og gemmer som wav-fil
    
    Returns:
        Sti til den gemte lydfil eller None ved fejl
    """
    if not USE_PYAUDIO and not USE_SOUNDDEVICE:
        logger.error("Lydoptagelse er ikke tilg√¶ngelig: B√•de PyAudio og sounddevice mangler")
        return None
        
    try:
        if USE_PYAUDIO:
            # PyAudio implementering
            p = pyaudio.PyAudio()
            stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)
            logger.info("Optager lyd med PyAudio...")
        
            frames = []
        
            # Forbedret st√∏jdetektering
            noise_samples = []
            for _ in range(10):  # √òget fra 5 til 10 samples for bedre baseline
                data = stream.read(CHUNK, exception_on_overflow=False)
                audio_data = np.frombuffer(data, dtype=np.int16)
                noise_samples.append(np.abs(audio_data).mean())
            noise_baseline = np.mean(noise_samples)
            silence_threshold = max(int(150), int(noise_baseline * 1.5))  # Forh√∏jet til 150 og 1.5x baseline
            
            # Resten af PyAudio implementeringen
            # ...
        elif USE_SOUNDDEVICE:
            # sounddevice implementering
            logger.info("Optager lyd med sounddevice...")
            print("\nüé§ Lytter... (Tal nu!)")  # Tydelig indikation for brugeren
            
            # Optag lyd i 5 sekunder
            duration = 5  # sekunder
            recording = sd.rec(int(duration * RATE), samplerate=RATE, channels=CHANNELS, dtype='int16')
            print("Optager...")
            sd.wait()  # Vent til optagelsen er f√¶rdig
            print("‚úÖ Optagelse afsluttet! Bearbejder...")
            
            # Gem lydfilen
            sf.write(TEMP_WAV, recording, RATE)
            logger.info(f"Lyd gemt til {TEMP_WAV}")
            return TEMP_WAV
        
        # Hvis vi bruger PyAudio, forts√¶t med den oprindelige implementering
        if USE_PYAUDIO:
            print("\nüé§ Lytter... (Tal nu!)")  # Tydelig indikation for brugeren
        
            silence_chunks = 0
            max_silence_chunks = int(2.5 * RATE / CHUNK)  # √òget til 2.5 sekunder (mere t√•lmodig)
            max_recording_chunks = int(15 * RATE / CHUNK)  # √òget til 15 sekunder (l√¶ngere optagelse)
            chunk_count = 0
            listening = True
            has_sound = False
            sound_chunks = 0
        
            # Vent p√• lyd frem for at starte med det samme
            print("Venter p√• tale...")
            waiting_for_speech = True
            waiting_timeout = int(5 * RATE / CHUNK)  # √òget til 5 sekunder ventetid
            waiting_count = 0
        
            while waiting_for_speech and waiting_count < waiting_timeout:
                data = stream.read(CHUNK, exception_on_overflow=False)
                audio_data = np.frombuffer(data, dtype=np.int16)
                amplitude = np.abs(audio_data).mean()
            
                if amplitude > silence_threshold * 1.8:  # S√¶nket fra 2 til 1.8 for lettere aktivering
                    waiting_for_speech = False
                    print("Tale detekteret! Optager...")
                    frames.append(data)  # Inkluder denne lydbit
                    has_sound = True
                    sound_chunks = 1
                else:
                    waiting_count += 1
        
            if waiting_count >= waiting_timeout:
                print("Ingen tale detekteret inden for tidsgr√¶nsen")
                return None
        
            # Hovedoptagelsesloop
            while listening:
                data = stream.read(CHUNK, exception_on_overflow=False)
                frames.append(data)
                chunk_count += 1
            
                # Tjek lydstyrke
                audio_data = np.frombuffer(data, dtype=np.int16)
                amplitude = np.abs(audio_data).mean()
            
                if amplitude > silence_threshold:
                    has_sound = True
                    sound_chunks += 1
                    silence_chunks = 0
                else:
                    silence_chunks += 1
                    if silence_chunks > max_silence_chunks and has_sound and sound_chunks > 2:
                        listening = False
                        logger.info("Stilhed detekteret, stopper optagelse")
            
                if chunk_count > max_recording_chunks:
                    listening = False
                    logger.info("Maksimal optagelsestid n√•et")
                
            # Luk PyAudio stream 
            stream.stop_stream()
            stream.close()
            p.terminate()
        
            if frames and has_sound and sound_chunks > 2:
                try:
                    # Gem lydfilen
                    wf = wave.open(TEMP_WAV, 'wb')
                    wf.setnchannels(CHANNELS)
                    wf.setsampwidth(p.get_sample_size(FORMAT))
                    wf.setframerate(RATE)
                    wf.writeframes(b''.join(frames))
                    wf.close()
                    logger.info(f"Lyd gemt til {TEMP_WAV}")
                    print("‚úÖ Optagelse afsluttet! Bearbejder...")
                    return TEMP_WAV
                except Exception as e:
                    logger.error(f"Fejl ved gem af lydfil: {e}")
                    return None
            else:
                logger.info("Ingen lyd detekteret eller for kort lyd")
                print("‚ùå Ingen brugbar lyd optaget")
                return None
                
    except Exception as e:
        logger.error(f"Fejl under optagelse: {e}")
        return None

def danish_text_cleanup(text: str) -> str:
    """
    Renser og forbereder dansk tekst for tekst-til-tale
    
    Args:
        text: Input tekst
        
    Returns:
        Renset tekst optimeret for dansk TTS
    """
    # Erstat specifikke ord/forkortelser for bedre udtale
    replacements = {
        "f.eks.": "for eksempel",
        "bl.a.": "blandt andet",
        "osv.": "og s√• videre",
        "dvs.": "det vil sige",
        "etc.": "etcetera",
        "ca.": "cirka",
        "tlf.": "telefon",
        "nr.": "nummer",
        "kl.": "klokken",
    }
    
    for orig, repl in replacements.items():
        text = text.replace(orig, repl)
    
    # Inds√¶t pauser ved kommaer og punktummer for mere naturlig tale
    text = text.replace(",", ", ")
    text = text.replace(".", ". ")
    
    # Fjern dobbelt-mellemrum
    while "  " in text:
        text = text.replace("  ", " ")
    
    return text

def play_sound_blocking(file_path: str) -> None:
    """
    Afspiller en lydfil blokerende
    
    Args:
        file_path: Sti til lydfilen der skal afspilles
    """
    try:
        playsound.playsound(file_path)
    except Exception as e:
        logger.error(f"Fejl under afspilning af lyd: {e}")

# Opdater den asynkrone wrapper til at vente p√• at lyden afspilles f√¶rdig
async def speak_async(text: str, lang: str = 'da') -> None:
    """
    Asynkron wrapper for speak der venter p√• at lyden afspilles f√¶rdig
    
    Args:
        text: Teksten der skal udtales
        lang: Sproget (default: 'da' for dansk)
    """
    # Forbered teksten til bedre TTS
    text = danish_text_cleanup(text)
    
    # Print output til konsollen (synlig feedback)
    print(f"üîä Jarvis: {text}")
    
    # Tjek cache f√∏rst
    text_hash = hashlib.md5(text.encode('utf-8')).hexdigest()
    os.makedirs(TTS_CACHE_DIR, exist_ok=True)
    cache_path = os.path.join(TTS_CACHE_DIR, f"{text_hash}.mp3")
    
    # Generer eller brug cache
    if not os.path.exists(cache_path):
        # Generer ny TTS
        logger.info(f"Genererer ny TTS for: {text[:50]}...")
        tts = gTTS(text=text, lang=lang, slow=False)
        
        # Brug midlertidigt filnavn
        with NamedTemporaryFile(suffix='.mp3', delete=False) as temp_file:
            temp_filename = temp_file.name
        
        # Gem til temp fil og flyt
        tts.save(temp_filename)
        os.replace(temp_filename, cache_path)
    else:
        logger.info(f"Bruger cached TTS for: {text[:50]}...")
    
    # Afspil lyden blokerende, men i en executor for at undg√• at blokere event loopet
    loop = asyncio.get_event_loop()
    await loop.run_in_executor(None, lambda: play_sound_blocking(cache_path))

# Genimplementer stream_speak
async def stream_speak(text: str, lang: str = 'da', wait_after: bool = True) -> None:
    """
    Streamer tale med mere naturlig rytme og feedback
    
    Args:
        text: Teksten der skal udtales
        lang: Sproget (default: 'da' for dansk)
        wait_after: Om der skal ventes efter tale
    """
    # Del teksten op i s√¶tninger
    sentences = re.split(r'(?<=[.!?]) +', text)
    
    # Fjern tomme s√¶tninger
    sentences = [s for s in sentences if s.strip()]
    
    # Hvis der er et sp√∏rgsm√•l eller en forventning om respons, tag h√∏jde for det
    expects_response = any(marker in text for marker in ["?", "Vil du", "Skal jeg", "Kan du"])
    
    # For meget korte tekster (fx "Ja", "Nej", "Okay"), brug normal speak
    if len(text) < 10 or len(sentences) <= 1:
        await speak_async(text, lang)
        # Vent efter kort svar hvis det ikke er et sp√∏rgsm√•l
        if wait_after and not expects_response:
            await asyncio.sleep(0.5)
        return
        
    # For l√¶ngere tekster, stream s√¶tningsvist
    total_sentences = len(sentences)
    
    for i, sentence in enumerate(sentences):
        if not sentence.strip():
            continue
        
        # For sidste s√¶tning, tjek om det er et sp√∏rgsm√•l eller forventning
        if i == total_sentences - 1 and expects_response:
            # Tilf√∏j lidt ekstra pause for at indikere vi venter p√• svar
            await speak_async(sentence, lang)
            if wait_after:
                await asyncio.sleep(0.5)  # Lidt l√¶ngere pause ved afventning af svar
        else:
            # Normal s√¶tning i en sekvens
            await speak_async(sentence, lang)
            
            # Kort pause mellem s√¶tninger, l√¶ngere hvis det er punktum
            if i < total_sentences - 1:  # Ikke p√• sidste s√¶tning
                pause_time = 0.3
                if sentence.strip().endswith('.'):
                    pause_time = 0.5  # L√¶ngere pause efter punktum
                elif sentence.strip().endswith(','):
                    pause_time = 0.2  # Kortere pause efter komma
                
                await asyncio.sleep(pause_time)
    
    # Hvis teksten indeholder et sp√∏rgsm√•l eller forventning, vent l√¶ngere
    if wait_after and expects_response:
        await asyncio.sleep(0.5)  # Giv brugeren tid til at svare

def speak(text: str, lang: str = 'da') -> None:
    """
    Synkron version af speak_async.
    Konverterer tekst til tale og afspiller den √∏jeblikkeligt.
    
    Args:
        text: Teksten der skal udtales
        lang: Sproget (default: dansk)
    """
    logger.info(f"TTS synkron: '{text}'")
    
    # Rens tekst
    text = danish_text_cleanup(text)
    
    # Generer et unikt filnavn baseret p√• tekst og sprog
    text_hash = hashlib.md5(text.encode('utf-8')).hexdigest()
    mp3_path = os.path.join(TTS_CACHE_DIR, f"{text_hash}.mp3")
    
    # Opret cache-mappe hvis den ikke eksisterer
    os.makedirs(TTS_CACHE_DIR, exist_ok=True)
    
    # Tjek om vi har en cache af denne tekst
    if not os.path.exists(mp3_path):
        try:
            tts = gTTS(text=text, lang=lang, slow=False)
            tts.save(mp3_path)
            logger.debug(f"TTS MP3 gemt til: {mp3_path}")
        except Exception as e:
            logger.error(f"Fejl ved generering af tale: {e}")
            return
    
    # Afspil lyden
    try:
        play_sound_blocking(mp3_path)
    except Exception as e:
        logger.error(f"Fejl ved afspilning af lyd: {e}")

# Async-versioner af funktionerne til brug med asyncio
async def transcribe_audio_async(file_path: str) -> Optional[str]:
    """Asynkron wrapper for transcribe_audio"""
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, lambda: transcribe_audio(file_path))

async def record_audio_async() -> Optional[str]:
    """Asynkron wrapper for record_audio"""
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, record_audio)

class SpeechHandler:
    """Klasse til h√•ndtering af tale-til-tekst og tekst-til-tale"""
    
    def __init__(self):
        # Initialiser STT model (Faster Whisper)
        logger.info("Indl√¶ser Whisper model...")
        self.stt_model = WhisperModel(
            model_size_or_path="small",
            device="cuda" if torch.cuda.is_available() else "cpu",
            compute_type="float16" if torch.cuda.is_available() else "int8"
        )
        
        # Initialiser pygame til lydafspilning
        pygame.mixer.init()
        
        # Cache mappe til TTS
        self.cache_dir = Path("cache/tts")
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # Lydindstillinger
        self.sample_rate = 16000
        self.channels = 1
    
    async def record_audio(self) -> str:
        """Optag lyd fra mikrofon"""
        logger.info("Optager...")
        
        # Start optagelse
        recording = sd.rec(
            int(30 * self.sample_rate),  # Max 30 sekunder
            samplerate=self.sample_rate,
            channels=self.channels,
            dtype=np.int16
        )
        
        sd.wait()  # Vent p√• optagelse er f√¶rdig
        
        # Gem lydfil
        temp_file = NamedTemporaryFile(suffix=".wav", delete=False)
        sf.write(temp_file.name, recording, self.sample_rate)
        
        return temp_file.name
    
    async def transcribe_audio(self, audio_path: str) -> str:
        """Konverter tale til tekst"""
        segments, _ = self.stt_model.transcribe(
            audio_path,
            language="da",
            beam_size=5
        )
        return " ".join([seg.text for seg in segments])
    
    async def speak_text(self, text: str) -> None:
        """Konverter tekst til tale og afspil"""
        if not text.strip():
            text = "Undskyld, jeg ved ikke hvad jeg skal svare. Kan du omformulere dit sp√∏rgsm√•l?"
            
        # Generer unik filsti i cache
        output_path = self.cache_dir / f"response_{hash(text)}.mp3"
        
        # Hvis ikke i cache, generer ny lydfil
        if not output_path.exists():
            tts = gTTS(text=text, lang="da")
            tts.save(str(output_path))
        
        # Afspil svar
        pygame.mixer.music.load(str(output_path))
        pygame.mixer.music.play()
        while pygame.mixer.music.get_busy():
            await asyncio.sleep(0.1)

# Global instance
speech_handler = SpeechHandler()